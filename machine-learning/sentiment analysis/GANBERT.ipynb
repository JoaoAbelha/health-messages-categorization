{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GANBERT.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyObj/NnkuUsg7yJIHammQxO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"3d4c14ef13ca46d8b1b55ac3380f867a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6bc14b35f2ab4e1e8adec5363dd59cbd","IPY_MODEL_3f0425dee6ac488192206373c0cf0a14","IPY_MODEL_4832d4f6a4564d01a38aa0961d8bddef"],"layout":"IPY_MODEL_4d30c3beaf5543d88ff306ca991745a8"}},"6bc14b35f2ab4e1e8adec5363dd59cbd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbea430faa4046d196fb3640e8b647ea","placeholder":"​","style":"IPY_MODEL_c175f473ec19446f800e94ab6b99bce5","value":"Downloading: 100%"}},"3f0425dee6ac488192206373c0cf0a14":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1cc7e0172d2c42b690110505eae4f5f8","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_59f76e069fb0430daa2e13a1e5a9e015","value":570}},"4832d4f6a4564d01a38aa0961d8bddef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5bc3e5a3a00744eda2c18579cf008760","placeholder":"​","style":"IPY_MODEL_4a14b03bb9264828a81d75e033fec397","value":" 570/570 [00:00&lt;00:00, 17.6kB/s]"}},"4d30c3beaf5543d88ff306ca991745a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbea430faa4046d196fb3640e8b647ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c175f473ec19446f800e94ab6b99bce5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1cc7e0172d2c42b690110505eae4f5f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59f76e069fb0430daa2e13a1e5a9e015":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5bc3e5a3a00744eda2c18579cf008760":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a14b03bb9264828a81d75e033fec397":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f7aadba956b420c9a615db68b46fa02":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99c48371717d46ee8e5975cdc595c59c","IPY_MODEL_5e45061a72a440e29d0043952e249c0b","IPY_MODEL_7ec77c71675d4e5395d4fe669014e3ed"],"layout":"IPY_MODEL_25ee10cdf8fb42af8e1cae39a36f9bd4"}},"99c48371717d46ee8e5975cdc595c59c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fc53edf80d24417bad4fc375a357b11","placeholder":"​","style":"IPY_MODEL_779493d8f49247668f3bb5815ac4e263","value":"Downloading: 100%"}},"5e45061a72a440e29d0043952e249c0b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2bffe485abe41e2a4f05e822fda7b2b","max":435779157,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3700526d005247c9844669c5ea149369","value":435779157}},"7ec77c71675d4e5395d4fe669014e3ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0473589b023480bb0bcbf4282dcba82","placeholder":"​","style":"IPY_MODEL_76c0abaaf78545bc86c0d05c1c421560","value":" 436M/436M [00:07&lt;00:00, 58.2MB/s]"}},"25ee10cdf8fb42af8e1cae39a36f9bd4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fc53edf80d24417bad4fc375a357b11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"779493d8f49247668f3bb5815ac4e263":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a2bffe485abe41e2a4f05e822fda7b2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3700526d005247c9844669c5ea149369":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d0473589b023480bb0bcbf4282dcba82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76c0abaaf78545bc86c0d05c1c421560":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a9aefe789f743e59c4d45996072d5f8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d7bbe6378dd3427088cc9d3a820e6b1d","IPY_MODEL_67d02e49b59547c1a51763e0960f9785","IPY_MODEL_225b9ea0af2d4591a145775d8438649d"],"layout":"IPY_MODEL_a187d81da73c496f869e2710253288f5"}},"d7bbe6378dd3427088cc9d3a820e6b1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6446a2f7fe8444e2a8c18f169425e414","placeholder":"​","style":"IPY_MODEL_7f69e37da8e94dc6a6520791d5c53e53","value":"Downloading: 100%"}},"67d02e49b59547c1a51763e0960f9785":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e752ff319ed14bada5d328f39037c0eb","max":213450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_be175c45493345edb8adb94af78d6254","value":213450}},"225b9ea0af2d4591a145775d8438649d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc48fcabcb92433aaa0a1af847830767","placeholder":"​","style":"IPY_MODEL_41ac49b8a54445f385b563211ff828a2","value":" 213k/213k [00:00&lt;00:00, 263kB/s]"}},"a187d81da73c496f869e2710253288f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6446a2f7fe8444e2a8c18f169425e414":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f69e37da8e94dc6a6520791d5c53e53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e752ff319ed14bada5d328f39037c0eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be175c45493345edb8adb94af78d6254":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fc48fcabcb92433aaa0a1af847830767":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41ac49b8a54445f385b563211ff828a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"62cf15bf1378473abc4b0630a85f791d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5e8e4086c88d4db6b9387ad8891ac9c9","IPY_MODEL_20a3e5a1dba14d7cba4c2c52594c150a","IPY_MODEL_7ace226d62314890a403d1ab5314f909"],"layout":"IPY_MODEL_c2d107f37861484f9a9fa7d070065a80"}},"5e8e4086c88d4db6b9387ad8891ac9c9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6ea32b9f2e941ed8782c689aa0f1ed2","placeholder":"​","style":"IPY_MODEL_9afb6140fd9e4e1d85b4fcb37d5b5cdd","value":"Downloading: 100%"}},"20a3e5a1dba14d7cba4c2c52594c150a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_05af670b64eb444b84c8b8fc4ce2083c","max":435797,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a975ad8d08734f6e9ecfb7e7c7d97a5a","value":435797}},"7ace226d62314890a403d1ab5314f909":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1be6e5a25f804a97bff1618b5d2106a2","placeholder":"​","style":"IPY_MODEL_fa997fa9a59a404085d53d87966fc718","value":" 436k/436k [00:01&lt;00:00, 501kB/s]"}},"c2d107f37861484f9a9fa7d070065a80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6ea32b9f2e941ed8782c689aa0f1ed2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9afb6140fd9e4e1d85b4fcb37d5b5cdd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05af670b64eb444b84c8b8fc4ce2083c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a975ad8d08734f6e9ecfb7e7c7d97a5a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1be6e5a25f804a97bff1618b5d2106a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa997fa9a59a404085d53d87966fc718":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install torch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A6NZPcRPnQz2","executionInfo":{"status":"ok","timestamp":1654868469879,"user_tz":-60,"elapsed":6172,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}},"outputId":"2ebb9dd2-26ee-4644-ec99-47ad063689da"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.2.0)\n"]}]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader\n"],"metadata":{"id":"IpS-QPPJnX5O","executionInfo":{"status":"ok","timestamp":1654868472935,"user_tz":-60,"elapsed":3059,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_b0Fe-lYmEya","executionInfo":{"status":"ok","timestamp":1654868472935,"user_tz":-60,"elapsed":13,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}},"outputId":"5ee0d448-b2ac-42bb-9794-02ec241d4b06"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n","torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n"]}],"source":["nb_samples = 100\n","features = torch.randn(nb_samples, 10)\n","labels = torch.empty(nb_samples, dtype=torch.long)\n","adjacency = torch.randn(nb_samples, 5)\n","laplacian = torch.randn(nb_samples, 7)\n","\n","dataset = TensorDataset(features, labels, adjacency, laplacian)\n","loader = DataLoader(\n","    dataset,\n","    batch_size=2\n",")\n","\n","for batch_idx, (x, y, a, l) in enumerate(loader):\n","    print(x.shape, y.shape, a.shape, l.shape)"]},{"cell_type":"code","source":["!pip install onnxruntime\n","!pip install onnx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KQEczA6S3FjS","executionInfo":{"status":"ok","timestamp":1654868482413,"user_tz":-60,"elapsed":9489,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}},"outputId":"2aaaf26f-b8aa-45b2-a468-dab6e36889e1"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting onnxruntime\n","  Downloading onnxruntime-1.11.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n","\u001b[K     |████████████████████████████████| 5.2 MB 24.3 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (3.17.3)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (2.0)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (1.21.6)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->onnxruntime) (1.15.0)\n","Installing collected packages: onnxruntime\n","Successfully installed onnxruntime-1.11.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting onnx\n","  Downloading onnx-1.11.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (12.8 MB)\n","\u001b[K     |████████████████████████████████| 12.8 MB 27.1 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (4.2.0)\n","Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx) (1.21.6)\n","Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.17.3)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.2->onnx) (1.15.0)\n","Installing collected packages: onnx\n","Successfully installed onnx-1.11.0\n"]}]},{"cell_type":"code","source":["!pip install transformers==4.3.2\n","import pandas as pd\n","import torch\n","import io\n","import torch.nn.functional as F\n","import random\n","import numpy as np\n","import time\n","import math\n","import datetime\n","import torch.nn as nn\n","from transformers import *\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","#!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n","#!pip install sentencepiece\n","\n","##Set random values\n","seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","if torch.cuda.is_available():\n","  torch.cuda.manual_seed_all(seed_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qfkG-HeN3Jza","executionInfo":{"status":"ok","timestamp":1654868496675,"user_tz":-60,"elapsed":14283,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}},"outputId":"60c9b899-eff5-48ca-c14c-e0a643ab1750"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.3.2\n","  Downloading transformers-4.3.2-py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 18.9 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2) (4.11.4)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 56.2 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2) (3.7.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2) (4.64.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 36.7 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.3.2) (4.2.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.3.2) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.3.2) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.2) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.2) (2022.5.18.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.2) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.2) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.2) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.2) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.2) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=89869a30b5db1bfb2733213ff68ef47ba9ab55d14506a09634dea9c9cb3cc9b3\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.3.2\n"]}]},{"cell_type":"code","source":["# If there's a GPU available...\n","if torch.cuda.is_available():    \n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4OAHodmE3NHq","executionInfo":{"status":"ok","timestamp":1654868496676,"user_tz":-60,"elapsed":21,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}},"outputId":"354f912b-f752-475f-87e2-7f1348e413c1"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"]}]},{"cell_type":"code","source":["#--------------------------------\n","#  Transformer parameters\n","#--------------------------------\n","max_seq_length = 64\n","batch_size = 32\n","\n","#--------------------------------\n","#  GAN-BERT specific parameters\n","#--------------------------------\n","# number of hidden layers in the generator, \n","# each of the size of the output space\n","num_hidden_layers_g = 1; \n","# number of hidden layers in the discriminator, \n","# each of the size of the input space\n","num_hidden_layers_d = 1; \n","# size of the generator's input noisy vectors\n","noise_size = 100\n","# dropout to be applied to discriminator's input vectors\n","out_dropout_rate = 0.2\n","\n","# Replicate labeled data to balance poorly represented datasets, \n","# e.g., less than 1% of labeled material\n","apply_balance = True\n","\n","#--------------------------------\n","#  Optimization parameters\n","#--------------------------------\n","learning_rate_discriminator = 5e-5\n","learning_rate_generator = 5e-5\n","epsilon = 1e-8\n","num_train_epochs = 5\n","multi_gpu = False\n","# Scheduler\n","apply_scheduler = False\n","warmup_proportion = 0.1\n","# Print\n","print_each_n_step = 10\n","\n","#--------------------------------\n","#  Adopted Tranformer model\n","#--------------------------------\n","# Since this version is compatible with Huggingface transformers, you can uncomment\n","# (or add) transformer models compatible with GAN\n","\n","model_name = \"bert-base-cased\"\n","#model_name = \"bert-base-uncased\"\n","#model_name = \"roberta-base\"\n","#model_name = \"albert-base-v2\"\n","#model_name = \"xlm-roberta-base\"\n","#model_name = \"amazon/bort\"\n","\n","#--------------------------------\n","#  Retrieve the TREC QC Dataset\n","#--------------------------------\n","! git clone https://github.com/crux82/ganbert\n","\n","#  NOTE: in this setting 50 classes are involved\n","labeled_file = \"./ganbert/data/labeled.tsv\"\n","unlabeled_file = \"./ganbert/data/unlabeled.tsv\"\n","test_filename = \"./ganbert/data/test.tsv\"\n","\n","# label_list = [\"UNK_UNK\",\"ABBR_abb\", \"ABBR_exp\", \"DESC_def\", \"DESC_desc\", \n","#               \"DESC_manner\", \"DESC_reason\", \"ENTY_animal\", \"ENTY_body\", \n","#               \"ENTY_color\", \"ENTY_cremat\", \"ENTY_currency\", \"ENTY_dismed\", \n","#               \"ENTY_event\", \"ENTY_food\", \"ENTY_instru\", \"ENTY_lang\", \n","#               \"ENTY_letter\", \"ENTY_other\", \"ENTY_plant\", \"ENTY_product\", \n","#               \"ENTY_religion\", \"ENTY_sport\", \"ENTY_substance\", \"ENTY_symbol\", \n","#               \"ENTY_techmeth\", \"ENTY_termeq\", \"ENTY_veh\", \"ENTY_word\", \"HUM_desc\", \n","#               \"HUM_gr\", \"HUM_ind\", \"HUM_title\", \"LOC_city\", \"LOC_country\", \n","#               \"LOC_mount\", \"LOC_other\", \"LOC_state\", \"NUM_code\", \"NUM_count\", \n","#               \"NUM_date\", \"NUM_dist\", \"NUM_money\", \"NUM_ord\", \"NUM_other\", \n","#               \"NUM_perc\", \"NUM_period\", \"NUM_speed\", \"NUM_temp\", \"NUM_volsize\", \n","#               \"NUM_weight\"]\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Z9X9rGy3Qhx","executionInfo":{"status":"ok","timestamp":1654868498440,"user_tz":-60,"elapsed":1781,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}},"outputId":"016a6e46-3dde-4dce-99c3-fe45f3497950"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'ganbert'...\n","remote: Enumerating objects: 77, done.\u001b[K\n","remote: Counting objects: 100% (38/38), done.\u001b[K\n","remote: Compressing objects: 100% (13/13), done.\u001b[K\n","remote: Total 77 (delta 32), reused 25 (delta 25), pack-reused 39\u001b[K\n","Unpacking objects: 100% (77/77), done.\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BiFjf7zw3kk5","executionInfo":{"status":"ok","timestamp":1654868776150,"user_tz":-60,"elapsed":277715,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}},"outputId":"048c8c2a-e5ea-48bf-d59e-7e411dfb919d"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["df = pd.read_csv('/content/gdrive/My Drive/Mestrado/sentiment_dataset.csv')"],"metadata":{"id":"-3D7HL5n3ucK","executionInfo":{"status":"ok","timestamp":1654868777283,"user_tz":-60,"elapsed":1138,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["df[df['sentiment'] == 'positive'].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ccco-iwaZTRx","executionInfo":{"status":"ok","timestamp":1654868777285,"user_tz":-60,"elapsed":56,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}},"outputId":"59d38c3d-3277-4d0a-8b4a-ef684877cbab"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(55, 3)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"vpRe-F2_33oK","executionInfo":{"status":"ok","timestamp":1654868777288,"user_tz":-60,"elapsed":47,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}},"outputId":"0c142539-3e1e-4b9f-c83c-848684bd594a"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0                                               text sentiment\n","0           0  Hello and hope you are doing well.Understand y...   neutral\n","1           1  It would be hard to see any significant abnorm...   neutral\n","2           2  Hi James,  I, too, go to bed by 10:00, then wa...   neutral\n","3           3  Hi, I am suffering from the same sleep problem...  negative\n","4           4      me too, it feels like its morning after 1hour   neutral"],"text/html":["\n","  <div id=\"df-3b6970c6-a772-4004-bdc1-a0c2bff5a786\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Hello and hope you are doing well.Understand y...</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>It would be hard to see any significant abnorm...</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Hi James,  I, too, go to bed by 10:00, then wa...</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Hi, I am suffering from the same sleep problem...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>me too, it feels like its morning after 1hour</td>\n","      <td>neutral</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b6970c6-a772-4004-bdc1-a0c2bff5a786')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3b6970c6-a772-4004-bdc1-a0c2bff5a786 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3b6970c6-a772-4004-bdc1-a0c2bff5a786');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["label_list = [\"neutral\", \"positive\", \"negative\", \"UNK\"]"],"metadata":{"id":"iDSYaezX3VU4","executionInfo":{"status":"ok","timestamp":1654868777290,"user_tz":-60,"elapsed":34,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Defining function to format the dataset to be used in the dataloader\n","def get_examples(df):\n","\n","    examples = []\n","\n","    # iterate through each row\n","    for index, row in df.iterrows():\n","        examples.append((row['text'], row['sentiment']))\n","\n","    return examples"],"metadata":{"id":"w7YHSVPm32tC","executionInfo":{"status":"ok","timestamp":1654868777292,"user_tz":-60,"elapsed":31,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","df_train, df_test = train_test_split(df, test_size=0.2, stratify=df['sentiment'])\n","\n","labeled_examples = get_examples(df_train)\n","test_examples = get_examples(df_test)"],"metadata":{"id":"EezuoDE439Uw","executionInfo":{"status":"ok","timestamp":1654868777295,"user_tz":-60,"elapsed":32,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["df_train.groupby('sentiment').count(), df_test.groupby('sentiment').count()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qGsf_BtpY8fw","executionInfo":{"status":"ok","timestamp":1654868777296,"user_tz":-60,"elapsed":33,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}},"outputId":"67e65a55-06e9-407f-b9cd-adae07f9d659"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(           Unnamed: 0  text\n"," sentiment                  \n"," negative          113   113\n"," neutral           232   232\n"," positive           44    44,            Unnamed: 0  text\n"," sentiment                  \n"," negative           29    29\n"," neutral            58    58\n"," positive           11    11)"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["len(test_examples)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RkKMAXUtT6on","executionInfo":{"status":"ok","timestamp":1654868778117,"user_tz":-60,"elapsed":849,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}},"outputId":"570d0443-ae87-4f5f-ffbe-fcd1df17738f"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["98"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["df_unlabeled =  pd.read_csv('/content/gdrive/My Drive/Mestrado/semi_supervised_learning.csv')"],"metadata":{"id":"wOTsZi-mL4ma","executionInfo":{"status":"ok","timestamp":1654868779655,"user_tz":-60,"elapsed":1539,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# Change each of the sentiment for unlabeled data to Unknown\n","for i in df_unlabeled.index:\n","    df_unlabeled.at[i, \"sentiment\"] = 'UNK'"],"metadata":{"id":"OBLKF3OiNKOS","executionInfo":{"status":"ok","timestamp":1654868780222,"user_tz":-60,"elapsed":571,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["unlabeled_examples = get_examples(df_unlabeled)"],"metadata":{"id":"kYV1xRvM4kMx","executionInfo":{"status":"ok","timestamp":1654868782717,"user_tz":-60,"elapsed":1865,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["transformer = AutoModel.from_pretrained(model_name)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)"],"metadata":{"id":"IyZXabwe4HJZ","executionInfo":{"status":"ok","timestamp":1654868800034,"user_tz":-60,"elapsed":17333,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}},"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["3d4c14ef13ca46d8b1b55ac3380f867a","6bc14b35f2ab4e1e8adec5363dd59cbd","3f0425dee6ac488192206373c0cf0a14","4832d4f6a4564d01a38aa0961d8bddef","4d30c3beaf5543d88ff306ca991745a8","cbea430faa4046d196fb3640e8b647ea","c175f473ec19446f800e94ab6b99bce5","1cc7e0172d2c42b690110505eae4f5f8","59f76e069fb0430daa2e13a1e5a9e015","5bc3e5a3a00744eda2c18579cf008760","4a14b03bb9264828a81d75e033fec397","6f7aadba956b420c9a615db68b46fa02","99c48371717d46ee8e5975cdc595c59c","5e45061a72a440e29d0043952e249c0b","7ec77c71675d4e5395d4fe669014e3ed","25ee10cdf8fb42af8e1cae39a36f9bd4","1fc53edf80d24417bad4fc375a357b11","779493d8f49247668f3bb5815ac4e263","a2bffe485abe41e2a4f05e822fda7b2b","3700526d005247c9844669c5ea149369","d0473589b023480bb0bcbf4282dcba82","76c0abaaf78545bc86c0d05c1c421560","5a9aefe789f743e59c4d45996072d5f8","d7bbe6378dd3427088cc9d3a820e6b1d","67d02e49b59547c1a51763e0960f9785","225b9ea0af2d4591a145775d8438649d","a187d81da73c496f869e2710253288f5","6446a2f7fe8444e2a8c18f169425e414","7f69e37da8e94dc6a6520791d5c53e53","e752ff319ed14bada5d328f39037c0eb","be175c45493345edb8adb94af78d6254","fc48fcabcb92433aaa0a1af847830767","41ac49b8a54445f385b563211ff828a2","62cf15bf1378473abc4b0630a85f791d","5e8e4086c88d4db6b9387ad8891ac9c9","20a3e5a1dba14d7cba4c2c52594c150a","7ace226d62314890a403d1ab5314f909","c2d107f37861484f9a9fa7d070065a80","d6ea32b9f2e941ed8782c689aa0f1ed2","9afb6140fd9e4e1d85b4fcb37d5b5cdd","05af670b64eb444b84c8b8fc4ce2083c","a975ad8d08734f6e9ecfb7e7c7d97a5a","1be6e5a25f804a97bff1618b5d2106a2","fa997fa9a59a404085d53d87966fc718"]},"outputId":"f55df6e9-3274-4c57-bf8a-b7bd441fbc43"},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d4c14ef13ca46d8b1b55ac3380f867a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f7aadba956b420c9a615db68b46fa02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a9aefe789f743e59c4d45996072d5f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62cf15bf1378473abc4b0630a85f791d"}},"metadata":{}}]},{"cell_type":"code","source":["def generate_data_loader(input_examples, label_masks, label_map, do_shuffle = False, balance_label_examples = False):\n","  '''\n","  Generate a Dataloader given the input examples, eventually masked if they are \n","  to be considered NOT labeled.\n","  '''\n","  examples = []\n","\n","  # Count the percentage of labeled examples  \n","  num_labeled_examples = 0\n","  for label_mask in label_masks:\n","    if label_mask: \n","      num_labeled_examples += 1\n","  label_mask_rate = num_labeled_examples/len(input_examples)\n","\n","  # if required it applies the balance\n","  for index, ex in enumerate(input_examples): \n","    if label_mask_rate == 1 or not balance_label_examples:\n","      examples.append((ex, label_masks[index]))\n","    else:\n","      # IT SIMULATE A LABELED EXAMPLE\n","      if label_masks[index]:\n","        balance = int(1/label_mask_rate)\n","        balance = int(math.log(balance,2))\n","        if balance < 1:\n","          balance = 1\n","        for b in range(0, int(balance)):\n","          examples.append((ex, label_masks[index]))\n","      else:\n","        examples.append((ex, label_masks[index]))\n","  \n","  #-----------------------------------------------\n","  # Generate input examples to the Transformer\n","  #-----------------------------------------------\n","  input_ids = []\n","  input_mask_array = []\n","  label_mask_array = []\n","  label_id_array = []\n","\n","  # Tokenization \n","  for (text, label_mask) in examples:\n","    encoded_sent = tokenizer.encode(text[0], add_special_tokens=True, max_length=max_seq_length, padding=\"max_length\", truncation=True)\n","    input_ids.append(encoded_sent)\n","    label_id_array.append(label_map[text[1]])\n","    label_mask_array.append(label_mask)\n","  \n","  # Attention to token (to ignore padded input wordpieces)\n","  for sent in input_ids:\n","    att_mask = [int(token_id > 0) for token_id in sent]                          \n","    input_mask_array.append(att_mask)\n","  # Convertion to Tensor\n","  input_ids = torch.tensor(input_ids) \n","  input_mask_array = torch.tensor(input_mask_array)\n","  label_id_array = torch.tensor(label_id_array, dtype=torch.long)\n","  label_mask_array = torch.tensor(label_mask_array)\n","\n","  # Building the TensorDataset\n","  dataset = TensorDataset(input_ids, input_mask_array, label_id_array, label_mask_array)\n","\n","  if do_shuffle:\n","    sampler = RandomSampler\n","  else:\n","    sampler = SequentialSampler\n","\n","  # Building the DataLoader\n","  return DataLoader(\n","              dataset,  # The training samples.\n","              sampler = sampler(dataset), \n","              batch_size = batch_size, # Trains with this batch size.\n","              drop_last=True) \n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"metadata":{"id":"-4Ly22dG4Z-C","executionInfo":{"status":"ok","timestamp":1654868800697,"user_tz":-60,"elapsed":679,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["label_map = {}\n","for (i, label) in enumerate(label_list):\n","  label_map[label] = i\n","#------------------------------\n","#   Load the train dataset\n","#------------------------------\n","train_examples = labeled_examples\n","#The labeled (train) dataset is assigned with a mask set to True\n","train_label_masks = np.ones(len(labeled_examples), dtype=bool)\n","#If unlabel examples are available\n","if unlabeled_examples:\n","  train_examples = train_examples + unlabeled_examples\n","  #The unlabeled (train) dataset is assigned with a mask set to False\n","  tmp_masks = np.zeros(len(unlabeled_examples), dtype=bool)\n","  train_label_masks = np.concatenate([train_label_masks,tmp_masks])\n","\n","train_dataloader = generate_data_loader(train_examples, train_label_masks, label_map, do_shuffle = True, balance_label_examples = apply_balance)\n","\n","#------------------------------\n","#   Load the test dataset\n","#------------------------------\n","#The labeled (test) dataset is assigned with a mask set to True\n","test_label_masks = np.ones(len(test_examples), dtype=bool)\n","\n","test_dataloader = generate_data_loader(test_examples, test_label_masks, label_map, do_shuffle = False, balance_label_examples = False)"],"metadata":{"id":"Rgl96ytI4baZ","executionInfo":{"status":"ok","timestamp":1654868813375,"user_tz":-60,"elapsed":12686,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["#------------------------------\n","#   The Generator as in \n","#   https://www.aclweb.org/anthology/2020.acl-main.191/\n","#   https://github.com/crux82/ganbert\n","#------------------------------\n","class Generator(nn.Module):\n","    def __init__(self, noise_size=100, output_size=512, hidden_sizes=[512], dropout_rate=0.1):\n","        super(Generator, self).__init__()\n","        layers = []\n","        hidden_sizes = [noise_size] + hidden_sizes\n","        for i in torch.arange(len(hidden_sizes)-1):\n","            layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n","\n","        layers.append(nn.Linear(hidden_sizes[-1],output_size))\n","        self.layers = nn.Sequential(*layers)\n","\n","    def forward(self, noise):\n","        output_rep = self.layers(noise)\n","        return output_rep\n","\n","#------------------------------\n","#   The Discriminator\n","#   https://www.aclweb.org/anthology/2020.acl-main.191/\n","#   https://github.com/crux82/ganbert\n","#------------------------------\n","class Discriminator(nn.Module):\n","    def __init__(self, input_size=512, hidden_sizes=[512], num_labels=2, dropout_rate=0.1):\n","        super(Discriminator, self).__init__()\n","        self.input_dropout = nn.Dropout(p=dropout_rate)\n","        layers = []\n","        hidden_sizes = [input_size] + hidden_sizes\n","        for i in torch.arange(len(hidden_sizes)-1):\n","            layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n","\n","        self.layers = nn.Sequential(*layers) #per il flatten\n","        self.logit = nn.Linear(hidden_sizes[-1],num_labels+1) # +1 for the probability of this sample being fake/real.\n","        self.softmax = nn.Softmax(dim=-1)\n","\n","    def forward(self, input_rep):\n","        input_rep = self.input_dropout(input_rep)\n","        last_rep = self.layers(input_rep)\n","        logits = self.logit(last_rep)\n","        probs = self.softmax(logits)\n","        return last_rep, logits, probs"],"metadata":{"id":"nQcej2Ea58Fb","executionInfo":{"status":"ok","timestamp":1654868813375,"user_tz":-60,"elapsed":16,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# The config file is required to get the dimension of the vector produced by \n","# the underlying transformer\n","config = AutoConfig.from_pretrained(model_name)\n","hidden_size = int(config.hidden_size)\n","# Define the number and width of hidden layers\n","hidden_levels_g = [hidden_size for i in torch.arange(0, num_hidden_layers_g)]\n","hidden_levels_d = [hidden_size for i in torch.arange(0, num_hidden_layers_d)]\n","\n","#-------------------------------------------------\n","#   Instantiate the Generator and Discriminator\n","#-------------------------------------------------\n","generator = Generator(noise_size=noise_size, output_size=hidden_size, hidden_sizes=hidden_levels_g, dropout_rate=out_dropout_rate)\n","discriminator = Discriminator(input_size=hidden_size, hidden_sizes=hidden_levels_d, num_labels=len(label_list), dropout_rate=out_dropout_rate)\n","\n","# Put everything in the GPU if available\n","if torch.cuda.is_available():    \n","  generator.cuda()\n","  discriminator.cuda()\n","  transformer.cuda()\n","  if multi_gpu:\n","    transformer = torch.nn.DataParallel(transformer)\n","\n","# print(config)"],"metadata":{"id":"-LWlMtq759QR","executionInfo":{"status":"ok","timestamp":1654868827829,"user_tz":-60,"elapsed":14469,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["training_stats = []\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","\n","#models parameters\n","transformer_vars = [i for i in transformer.parameters()]\n","d_vars = transformer_vars + [v for v in discriminator.parameters()]\n","g_vars = [v for v in generator.parameters()]\n","\n","#optimizer\n","dis_optimizer = torch.optim.AdamW(d_vars, lr=learning_rate_discriminator)\n","gen_optimizer = torch.optim.AdamW(g_vars, lr=learning_rate_generator) \n","\n","#scheduler\n","if apply_scheduler:\n","  num_train_examples = len(train_examples)\n","  num_train_steps = int(num_train_examples / batch_size * num_train_epochs)\n","  num_warmup_steps = int(num_train_steps * warmup_proportion)\n","\n","  scheduler_d = get_constant_schedule_with_warmup(dis_optimizer, \n","                                           num_warmup_steps = num_warmup_steps)\n","  scheduler_g = get_constant_schedule_with_warmup(gen_optimizer, \n","                                           num_warmup_steps = num_warmup_steps)\n","\n","# For each epoch...\n","for epoch_i in range(0, num_train_epochs):\n","    # ========================================\n","    #               Training\n","    # ========================================\n","    # Perform one full pass over the training set.\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, num_train_epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    tr_g_loss = 0\n","    tr_d_loss = 0\n","\n","    # Put the model into training mode.\n","    transformer.train() \n","    generator.train()\n","    discriminator.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every print_each_n_step batches.\n","        if step % print_each_n_step == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        b_label_mask = batch[3].to(device)\n","        \n","        # Encode real data in the Transformer\n","        model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n","        hidden_states = model_outputs[-1]\n","        \n","        # Generate fake data that should have the same distribution of the ones\n","        # encoded by the transformer. \n","        # First noisy input are used in input to the Generator\n","        noise = torch.zeros(b_input_ids.shape[0],noise_size, device=device).uniform_(0, 1)\n","        # Gnerate Fake data\n","        gen_rep = generator(noise)\n","\n","        # Generate the output of the Discriminator for real and fake data.\n","        # First, we put together the output of the tranformer and the generator\n","        disciminator_input = torch.cat([hidden_states, gen_rep], dim=0)\n","        # Then, we select the output of the disciminator\n","        features, logits, probs = discriminator(disciminator_input)\n","\n","        # Finally, we separate the discriminator's output for the real and fake\n","        # data\n","        features_list = torch.split(features, batch_size)\n","        D_real_features = features_list[0]\n","        D_fake_features = features_list[1]\n","        \n","        logits_list = torch.split(logits, batch_size)\n","        D_real_logits = logits_list[0]\n","        D_fake_logits = logits_list[1]\n","        \n","        probs_list = torch.split(probs, batch_size)\n","        D_real_probs = probs_list[0]\n","        D_fake_probs = probs_list[1]\n","\n","        #---------------------------------\n","        #  LOSS evaluation\n","        #---------------------------------\n","        # Generator's LOSS estimation\n","        g_loss_d = -1 * torch.mean(torch.log(1 - D_fake_probs[:,-1] + epsilon))\n","        g_feat_reg = torch.mean(torch.pow(torch.mean(D_real_features, dim=0) - torch.mean(D_fake_features, dim=0), 2))\n","        g_loss = g_loss_d + g_feat_reg\n","  \n","        # Disciminator's LOSS estimation\n","        logits = D_real_logits[:,0:-1]\n","        log_probs = F.log_softmax(logits, dim=-1)\n","        # The discriminator provides an output for labeled and unlabeled real data\n","        # so the loss evaluated for unlabeled data is ignored (masked)\n","        label2one_hot = torch.nn.functional.one_hot(b_labels, len(label_list))\n","        per_example_loss = -torch.sum(label2one_hot * log_probs, dim=-1)\n","        per_example_loss = torch.masked_select(per_example_loss, b_label_mask.to(device))\n","        labeled_example_count = per_example_loss.type(torch.float32).numel()\n","\n","        # It may be the case that a batch does not contain labeled examples, \n","        # so the \"supervised loss\" in this case is not evaluated\n","        if labeled_example_count == 0:\n","          D_L_Supervised = 0\n","        else:\n","          D_L_Supervised = torch.div(torch.sum(per_example_loss.to(device)), labeled_example_count)\n","                 \n","        D_L_unsupervised1U = -1 * torch.mean(torch.log(1 - D_real_probs[:, -1] + epsilon))\n","        D_L_unsupervised2U = -1 * torch.mean(torch.log(D_fake_probs[:, -1] + epsilon))\n","        d_loss = D_L_Supervised + D_L_unsupervised1U + D_L_unsupervised2U\n","\n","        #---------------------------------\n","        #  OPTIMIZATION\n","        #---------------------------------\n","        # Avoid gradient accumulation\n","        gen_optimizer.zero_grad()\n","        dis_optimizer.zero_grad()\n","\n","        # Calculate weigth updates\n","        # retain_graph=True is required since the underlying graph will be deleted after backward\n","        g_loss.backward(retain_graph=True)\n","        d_loss.backward() \n","        \n","        # Apply modifications\n","        gen_optimizer.step()\n","        dis_optimizer.step()\n","   \n","        # A detail log of the individual losses\n","        #print(\"{0:.4f}\\t{1:.4f}\\t{2:.4f}\\t{3:.4f}\\t{4:.4f}\".\n","        #      format(D_L_Supervised, D_L_unsupervised1U, D_L_unsupervised2U,\n","        #             g_loss_d, g_feat_reg))\n","\n","        # Save the losses to print them later\n","        tr_g_loss += g_loss.item()\n","        tr_d_loss += d_loss.item()\n","\n","        # Update the learning rate with the scheduler\n","        if apply_scheduler:\n","          scheduler_d.step()\n","          scheduler_g.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss_g = tr_g_loss / len(train_dataloader)\n","    avg_train_loss_d = tr_d_loss / len(train_dataloader)             \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss generetor: {0:.3f}\".format(avg_train_loss_g))\n","    print(\"  Average training loss discriminator: {0:.3f}\".format(avg_train_loss_d))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","\n","    print(\"Saving the models...............................\")\n","    # Saving the model\n","    torch.save(transformer, 'transformer')\n","    torch.save(discriminator, 'discriminator')\n","\n","        \n","    # ========================================\n","    #     TEST ON THE EVALUATION DATASET\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our test set.\n","    print(\"\")\n","    print(\"Running Test...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    transformer.eval() #maybe redundant\n","    discriminator.eval()\n","    generator.eval()\n","\n","    # Tracking variables \n","    total_test_accuracy = 0\n","   \n","    total_test_loss = 0\n","    nb_test_steps = 0\n","\n","    all_preds = []\n","    all_labels_ids = []\n","\n","    #loss\n","    nll_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n","\n","    # Evaluate data for one epoch\n","    for batch in test_dataloader:\n","        # Unpack this training batch from our dataloader. \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():        \n","            model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n","            hidden_states = model_outputs[-1]\n","            _, logits, probs = discriminator(hidden_states)\n","            ###log_probs = F.log_softmax(probs[:,1:], dim=-1)\n","            filtered_logits = logits[:,0:-1]\n","            # Accumulate the test loss.\n","            total_test_loss += nll_loss(filtered_logits, b_labels)\n","            \n","        # Accumulate the predictions and the input labels\n","        _, preds = torch.max(filtered_logits, 1)\n","        print(\"preds\", preds)\n","        all_preds += preds.detach().cpu()\n","        all_labels_ids += b_labels.detach().cpu()\n","\n","\n","    # Report the final accuracy for this validation run.\n","    all_preds = torch.stack(all_preds).numpy()\n","    all_labels_ids = torch.stack(all_labels_ids).numpy()\n","    test_accuracy = np.sum(all_preds == all_labels_ids) / len(all_preds)\n","    print(\"  Accuracy: {0:.3f}\".format(test_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_test_loss = total_test_loss / len(test_dataloader)\n","    avg_test_loss = avg_test_loss.item()\n","    \n","    # Measure how long the validation run took.\n","    test_time = format_time(time.time() - t0)\n","    \n","    print(\"  Test Loss: {0:.3f}\".format(avg_test_loss))\n","    print(\"  Test took: {:}\".format(test_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss generator': avg_train_loss_g,\n","            'Training Loss discriminator': avg_train_loss_d,\n","            'Valid. Loss': avg_test_loss,\n","            'Valid. Accur.': test_accuracy,\n","            'Training Time': training_time,\n","            'Test Time': test_time\n","        }\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g7Q_B9gB7eOR","executionInfo":{"status":"ok","timestamp":1654871602966,"user_tz":-60,"elapsed":2775159,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}},"outputId":"1a81500c-e714-4599-81ce-fc46efdd9014"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 5 ========\n","Training...\n","  Batch    10  of    988.    Elapsed: 0:00:05.\n","  Batch    20  of    988.    Elapsed: 0:00:10.\n","  Batch    30  of    988.    Elapsed: 0:00:15.\n","  Batch    40  of    988.    Elapsed: 0:00:20.\n","  Batch    50  of    988.    Elapsed: 0:00:26.\n","  Batch    60  of    988.    Elapsed: 0:00:31.\n","  Batch    70  of    988.    Elapsed: 0:00:36.\n","  Batch    80  of    988.    Elapsed: 0:00:41.\n","  Batch    90  of    988.    Elapsed: 0:00:46.\n","  Batch   100  of    988.    Elapsed: 0:00:52.\n","  Batch   110  of    988.    Elapsed: 0:00:57.\n","  Batch   120  of    988.    Elapsed: 0:01:02.\n","  Batch   130  of    988.    Elapsed: 0:01:08.\n","  Batch   140  of    988.    Elapsed: 0:01:13.\n","  Batch   150  of    988.    Elapsed: 0:01:19.\n","  Batch   160  of    988.    Elapsed: 0:01:24.\n","  Batch   170  of    988.    Elapsed: 0:01:30.\n","  Batch   180  of    988.    Elapsed: 0:01:35.\n","  Batch   190  of    988.    Elapsed: 0:01:41.\n","  Batch   200  of    988.    Elapsed: 0:01:47.\n","  Batch   210  of    988.    Elapsed: 0:01:52.\n","  Batch   220  of    988.    Elapsed: 0:01:58.\n","  Batch   230  of    988.    Elapsed: 0:02:04.\n","  Batch   240  of    988.    Elapsed: 0:02:10.\n","  Batch   250  of    988.    Elapsed: 0:02:15.\n","  Batch   260  of    988.    Elapsed: 0:02:21.\n","  Batch   270  of    988.    Elapsed: 0:02:27.\n","  Batch   280  of    988.    Elapsed: 0:02:32.\n","  Batch   290  of    988.    Elapsed: 0:02:38.\n","  Batch   300  of    988.    Elapsed: 0:02:43.\n","  Batch   310  of    988.    Elapsed: 0:02:49.\n","  Batch   320  of    988.    Elapsed: 0:02:55.\n","  Batch   330  of    988.    Elapsed: 0:03:00.\n","  Batch   340  of    988.    Elapsed: 0:03:06.\n","  Batch   350  of    988.    Elapsed: 0:03:11.\n","  Batch   360  of    988.    Elapsed: 0:03:17.\n","  Batch   370  of    988.    Elapsed: 0:03:23.\n","  Batch   380  of    988.    Elapsed: 0:03:28.\n","  Batch   390  of    988.    Elapsed: 0:03:34.\n","  Batch   400  of    988.    Elapsed: 0:03:40.\n","  Batch   410  of    988.    Elapsed: 0:03:45.\n","  Batch   420  of    988.    Elapsed: 0:03:51.\n","  Batch   430  of    988.    Elapsed: 0:03:56.\n","  Batch   440  of    988.    Elapsed: 0:04:02.\n","  Batch   450  of    988.    Elapsed: 0:04:08.\n","  Batch   460  of    988.    Elapsed: 0:04:13.\n","  Batch   470  of    988.    Elapsed: 0:04:19.\n","  Batch   480  of    988.    Elapsed: 0:04:25.\n","  Batch   490  of    988.    Elapsed: 0:04:30.\n","  Batch   500  of    988.    Elapsed: 0:04:36.\n","  Batch   510  of    988.    Elapsed: 0:04:41.\n","  Batch   520  of    988.    Elapsed: 0:04:47.\n","  Batch   530  of    988.    Elapsed: 0:04:53.\n","  Batch   540  of    988.    Elapsed: 0:04:58.\n","  Batch   550  of    988.    Elapsed: 0:05:04.\n","  Batch   560  of    988.    Elapsed: 0:05:10.\n","  Batch   570  of    988.    Elapsed: 0:05:15.\n","  Batch   580  of    988.    Elapsed: 0:05:21.\n","  Batch   590  of    988.    Elapsed: 0:05:27.\n","  Batch   600  of    988.    Elapsed: 0:05:32.\n","  Batch   610  of    988.    Elapsed: 0:05:38.\n","  Batch   620  of    988.    Elapsed: 0:05:44.\n","  Batch   630  of    988.    Elapsed: 0:05:49.\n","  Batch   640  of    988.    Elapsed: 0:05:55.\n","  Batch   650  of    988.    Elapsed: 0:06:01.\n","  Batch   660  of    988.    Elapsed: 0:06:06.\n","  Batch   670  of    988.    Elapsed: 0:06:12.\n","  Batch   680  of    988.    Elapsed: 0:06:17.\n","  Batch   690  of    988.    Elapsed: 0:06:23.\n","  Batch   700  of    988.    Elapsed: 0:06:29.\n","  Batch   710  of    988.    Elapsed: 0:06:34.\n","  Batch   720  of    988.    Elapsed: 0:06:40.\n","  Batch   730  of    988.    Elapsed: 0:06:46.\n","  Batch   740  of    988.    Elapsed: 0:06:51.\n","  Batch   750  of    988.    Elapsed: 0:06:57.\n","  Batch   760  of    988.    Elapsed: 0:07:02.\n","  Batch   770  of    988.    Elapsed: 0:07:08.\n","  Batch   780  of    988.    Elapsed: 0:07:14.\n","  Batch   790  of    988.    Elapsed: 0:07:19.\n","  Batch   800  of    988.    Elapsed: 0:07:25.\n","  Batch   810  of    988.    Elapsed: 0:07:30.\n","  Batch   820  of    988.    Elapsed: 0:07:36.\n","  Batch   830  of    988.    Elapsed: 0:07:42.\n","  Batch   840  of    988.    Elapsed: 0:07:47.\n","  Batch   850  of    988.    Elapsed: 0:07:53.\n","  Batch   860  of    988.    Elapsed: 0:07:58.\n","  Batch   870  of    988.    Elapsed: 0:08:04.\n","  Batch   880  of    988.    Elapsed: 0:08:10.\n","  Batch   890  of    988.    Elapsed: 0:08:15.\n","  Batch   900  of    988.    Elapsed: 0:08:21.\n","  Batch   910  of    988.    Elapsed: 0:08:27.\n","  Batch   920  of    988.    Elapsed: 0:08:32.\n","  Batch   930  of    988.    Elapsed: 0:08:38.\n","  Batch   940  of    988.    Elapsed: 0:08:43.\n","  Batch   950  of    988.    Elapsed: 0:08:49.\n","  Batch   960  of    988.    Elapsed: 0:08:55.\n","  Batch   970  of    988.    Elapsed: 0:09:00.\n","  Batch   980  of    988.    Elapsed: 0:09:06.\n","\n","  Average training loss generetor: 0.722\n","  Average training loss discriminator: 1.574\n","  Training epcoh took: 0:09:10\n","Saving the models...............................\n","\n","Running Test...\n","preds tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","preds tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","preds tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","  Accuracy: 0.594\n","  Test Loss: 0.929\n","  Test took: 0:00:00\n","\n","======== Epoch 2 / 5 ========\n","Training...\n","  Batch    10  of    988.    Elapsed: 0:00:06.\n","  Batch    20  of    988.    Elapsed: 0:00:11.\n","  Batch    30  of    988.    Elapsed: 0:00:17.\n","  Batch    40  of    988.    Elapsed: 0:00:22.\n","  Batch    50  of    988.    Elapsed: 0:00:28.\n","  Batch    60  of    988.    Elapsed: 0:00:34.\n","  Batch    70  of    988.    Elapsed: 0:00:39.\n","  Batch    80  of    988.    Elapsed: 0:00:45.\n","  Batch    90  of    988.    Elapsed: 0:00:51.\n","  Batch   100  of    988.    Elapsed: 0:00:56.\n","  Batch   110  of    988.    Elapsed: 0:01:02.\n","  Batch   120  of    988.    Elapsed: 0:01:07.\n","  Batch   130  of    988.    Elapsed: 0:01:13.\n","  Batch   140  of    988.    Elapsed: 0:01:19.\n","  Batch   150  of    988.    Elapsed: 0:01:24.\n","  Batch   160  of    988.    Elapsed: 0:01:30.\n","  Batch   170  of    988.    Elapsed: 0:01:35.\n","  Batch   180  of    988.    Elapsed: 0:01:41.\n","  Batch   190  of    988.    Elapsed: 0:01:47.\n","  Batch   200  of    988.    Elapsed: 0:01:52.\n","  Batch   210  of    988.    Elapsed: 0:01:58.\n","  Batch   220  of    988.    Elapsed: 0:02:03.\n","  Batch   230  of    988.    Elapsed: 0:02:09.\n","  Batch   240  of    988.    Elapsed: 0:02:15.\n","  Batch   250  of    988.    Elapsed: 0:02:20.\n","  Batch   260  of    988.    Elapsed: 0:02:26.\n","  Batch   270  of    988.    Elapsed: 0:02:31.\n","  Batch   280  of    988.    Elapsed: 0:02:37.\n","  Batch   290  of    988.    Elapsed: 0:02:43.\n","  Batch   300  of    988.    Elapsed: 0:02:48.\n","  Batch   310  of    988.    Elapsed: 0:02:54.\n","  Batch   320  of    988.    Elapsed: 0:03:00.\n","  Batch   330  of    988.    Elapsed: 0:03:05.\n","  Batch   340  of    988.    Elapsed: 0:03:11.\n","  Batch   350  of    988.    Elapsed: 0:03:16.\n","  Batch   360  of    988.    Elapsed: 0:03:22.\n","  Batch   370  of    988.    Elapsed: 0:03:28.\n","  Batch   380  of    988.    Elapsed: 0:03:33.\n","  Batch   390  of    988.    Elapsed: 0:03:39.\n","  Batch   400  of    988.    Elapsed: 0:03:45.\n","  Batch   410  of    988.    Elapsed: 0:03:50.\n","  Batch   420  of    988.    Elapsed: 0:03:56.\n","  Batch   430  of    988.    Elapsed: 0:04:01.\n","  Batch   440  of    988.    Elapsed: 0:04:07.\n","  Batch   450  of    988.    Elapsed: 0:04:13.\n","  Batch   460  of    988.    Elapsed: 0:04:18.\n","  Batch   470  of    988.    Elapsed: 0:04:24.\n","  Batch   480  of    988.    Elapsed: 0:04:29.\n","  Batch   490  of    988.    Elapsed: 0:04:35.\n","  Batch   500  of    988.    Elapsed: 0:04:41.\n","  Batch   510  of    988.    Elapsed: 0:04:46.\n","  Batch   520  of    988.    Elapsed: 0:04:52.\n","  Batch   530  of    988.    Elapsed: 0:04:57.\n","  Batch   540  of    988.    Elapsed: 0:05:03.\n","  Batch   550  of    988.    Elapsed: 0:05:09.\n","  Batch   560  of    988.    Elapsed: 0:05:14.\n","  Batch   570  of    988.    Elapsed: 0:05:20.\n","  Batch   580  of    988.    Elapsed: 0:05:25.\n","  Batch   590  of    988.    Elapsed: 0:05:31.\n","  Batch   600  of    988.    Elapsed: 0:05:37.\n","  Batch   610  of    988.    Elapsed: 0:05:42.\n","  Batch   620  of    988.    Elapsed: 0:05:48.\n","  Batch   630  of    988.    Elapsed: 0:05:54.\n","  Batch   640  of    988.    Elapsed: 0:05:59.\n","  Batch   650  of    988.    Elapsed: 0:06:05.\n","  Batch   660  of    988.    Elapsed: 0:06:10.\n","  Batch   670  of    988.    Elapsed: 0:06:16.\n","  Batch   680  of    988.    Elapsed: 0:06:22.\n","  Batch   690  of    988.    Elapsed: 0:06:27.\n","  Batch   700  of    988.    Elapsed: 0:06:33.\n","  Batch   710  of    988.    Elapsed: 0:06:38.\n","  Batch   720  of    988.    Elapsed: 0:06:44.\n","  Batch   730  of    988.    Elapsed: 0:06:50.\n","  Batch   740  of    988.    Elapsed: 0:06:55.\n","  Batch   750  of    988.    Elapsed: 0:07:01.\n","  Batch   760  of    988.    Elapsed: 0:07:06.\n","  Batch   770  of    988.    Elapsed: 0:07:12.\n","  Batch   780  of    988.    Elapsed: 0:07:18.\n","  Batch   790  of    988.    Elapsed: 0:07:23.\n","  Batch   800  of    988.    Elapsed: 0:07:29.\n","  Batch   810  of    988.    Elapsed: 0:07:34.\n","  Batch   820  of    988.    Elapsed: 0:07:40.\n","  Batch   830  of    988.    Elapsed: 0:07:46.\n","  Batch   840  of    988.    Elapsed: 0:07:51.\n","  Batch   850  of    988.    Elapsed: 0:07:57.\n","  Batch   860  of    988.    Elapsed: 0:08:02.\n","  Batch   870  of    988.    Elapsed: 0:08:08.\n","  Batch   880  of    988.    Elapsed: 0:08:14.\n","  Batch   890  of    988.    Elapsed: 0:08:19.\n","  Batch   900  of    988.    Elapsed: 0:08:25.\n","  Batch   910  of    988.    Elapsed: 0:08:30.\n","  Batch   920  of    988.    Elapsed: 0:08:36.\n","  Batch   930  of    988.    Elapsed: 0:08:42.\n","  Batch   940  of    988.    Elapsed: 0:08:47.\n","  Batch   950  of    988.    Elapsed: 0:08:53.\n","  Batch   960  of    988.    Elapsed: 0:08:58.\n","  Batch   970  of    988.    Elapsed: 0:09:04.\n","  Batch   980  of    988.    Elapsed: 0:09:10.\n","\n","  Average training loss generetor: 0.711\n","  Average training loss discriminator: 1.579\n","  Training epcoh took: 0:09:14\n","Saving the models...............................\n","\n","Running Test...\n","preds tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","preds tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","preds tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","  Accuracy: 0.594\n","  Test Loss: 0.920\n","  Test took: 0:00:00\n","\n","======== Epoch 3 / 5 ========\n","Training...\n","  Batch    10  of    988.    Elapsed: 0:00:06.\n","  Batch    20  of    988.    Elapsed: 0:00:11.\n","  Batch    30  of    988.    Elapsed: 0:00:17.\n","  Batch    40  of    988.    Elapsed: 0:00:22.\n","  Batch    50  of    988.    Elapsed: 0:00:28.\n","  Batch    60  of    988.    Elapsed: 0:00:34.\n","  Batch    70  of    988.    Elapsed: 0:00:39.\n","  Batch    80  of    988.    Elapsed: 0:00:45.\n","  Batch    90  of    988.    Elapsed: 0:00:51.\n","  Batch   100  of    988.    Elapsed: 0:00:56.\n","  Batch   110  of    988.    Elapsed: 0:01:02.\n","  Batch   120  of    988.    Elapsed: 0:01:07.\n","  Batch   130  of    988.    Elapsed: 0:01:13.\n","  Batch   140  of    988.    Elapsed: 0:01:18.\n","  Batch   150  of    988.    Elapsed: 0:01:24.\n","  Batch   160  of    988.    Elapsed: 0:01:30.\n","  Batch   170  of    988.    Elapsed: 0:01:35.\n","  Batch   180  of    988.    Elapsed: 0:01:41.\n","  Batch   190  of    988.    Elapsed: 0:01:46.\n","  Batch   200  of    988.    Elapsed: 0:01:52.\n","  Batch   210  of    988.    Elapsed: 0:01:58.\n","  Batch   220  of    988.    Elapsed: 0:02:03.\n","  Batch   230  of    988.    Elapsed: 0:02:09.\n","  Batch   240  of    988.    Elapsed: 0:02:14.\n","  Batch   250  of    988.    Elapsed: 0:02:20.\n","  Batch   260  of    988.    Elapsed: 0:02:26.\n","  Batch   270  of    988.    Elapsed: 0:02:31.\n","  Batch   280  of    988.    Elapsed: 0:02:37.\n","  Batch   290  of    988.    Elapsed: 0:02:42.\n","  Batch   300  of    988.    Elapsed: 0:02:48.\n","  Batch   310  of    988.    Elapsed: 0:02:54.\n","  Batch   320  of    988.    Elapsed: 0:02:59.\n","  Batch   330  of    988.    Elapsed: 0:03:05.\n","  Batch   340  of    988.    Elapsed: 0:03:10.\n","  Batch   350  of    988.    Elapsed: 0:03:16.\n","  Batch   360  of    988.    Elapsed: 0:03:22.\n","  Batch   370  of    988.    Elapsed: 0:03:27.\n","  Batch   380  of    988.    Elapsed: 0:03:33.\n","  Batch   390  of    988.    Elapsed: 0:03:39.\n","  Batch   400  of    988.    Elapsed: 0:03:44.\n","  Batch   410  of    988.    Elapsed: 0:03:50.\n","  Batch   420  of    988.    Elapsed: 0:03:55.\n","  Batch   430  of    988.    Elapsed: 0:04:01.\n","  Batch   440  of    988.    Elapsed: 0:04:07.\n","  Batch   450  of    988.    Elapsed: 0:04:12.\n","  Batch   460  of    988.    Elapsed: 0:04:18.\n","  Batch   470  of    988.    Elapsed: 0:04:23.\n","  Batch   480  of    988.    Elapsed: 0:04:29.\n","  Batch   490  of    988.    Elapsed: 0:04:35.\n","  Batch   500  of    988.    Elapsed: 0:04:40.\n","  Batch   510  of    988.    Elapsed: 0:04:46.\n","  Batch   520  of    988.    Elapsed: 0:04:51.\n","  Batch   530  of    988.    Elapsed: 0:04:57.\n","  Batch   540  of    988.    Elapsed: 0:05:03.\n","  Batch   550  of    988.    Elapsed: 0:05:08.\n","  Batch   560  of    988.    Elapsed: 0:05:14.\n","  Batch   570  of    988.    Elapsed: 0:05:19.\n","  Batch   580  of    988.    Elapsed: 0:05:25.\n","  Batch   590  of    988.    Elapsed: 0:05:31.\n","  Batch   600  of    988.    Elapsed: 0:05:36.\n","  Batch   610  of    988.    Elapsed: 0:05:42.\n","  Batch   620  of    988.    Elapsed: 0:05:48.\n","  Batch   630  of    988.    Elapsed: 0:05:53.\n","  Batch   640  of    988.    Elapsed: 0:05:59.\n","  Batch   650  of    988.    Elapsed: 0:06:04.\n","  Batch   660  of    988.    Elapsed: 0:06:10.\n","  Batch   670  of    988.    Elapsed: 0:06:16.\n","  Batch   680  of    988.    Elapsed: 0:06:21.\n","  Batch   690  of    988.    Elapsed: 0:06:27.\n","  Batch   700  of    988.    Elapsed: 0:06:33.\n","  Batch   710  of    988.    Elapsed: 0:06:38.\n","  Batch   720  of    988.    Elapsed: 0:06:44.\n","  Batch   730  of    988.    Elapsed: 0:06:49.\n","  Batch   740  of    988.    Elapsed: 0:06:55.\n","  Batch   750  of    988.    Elapsed: 0:07:01.\n","  Batch   760  of    988.    Elapsed: 0:07:06.\n","  Batch   770  of    988.    Elapsed: 0:07:12.\n","  Batch   780  of    988.    Elapsed: 0:07:17.\n","  Batch   790  of    988.    Elapsed: 0:07:23.\n","  Batch   800  of    988.    Elapsed: 0:07:29.\n","  Batch   810  of    988.    Elapsed: 0:07:34.\n","  Batch   820  of    988.    Elapsed: 0:07:40.\n","  Batch   830  of    988.    Elapsed: 0:07:45.\n","  Batch   840  of    988.    Elapsed: 0:07:51.\n","  Batch   850  of    988.    Elapsed: 0:07:57.\n","  Batch   860  of    988.    Elapsed: 0:08:02.\n","  Batch   870  of    988.    Elapsed: 0:08:08.\n","  Batch   880  of    988.    Elapsed: 0:08:13.\n","  Batch   890  of    988.    Elapsed: 0:08:19.\n","  Batch   900  of    988.    Elapsed: 0:08:25.\n","  Batch   910  of    988.    Elapsed: 0:08:30.\n","  Batch   920  of    988.    Elapsed: 0:08:36.\n","  Batch   930  of    988.    Elapsed: 0:08:41.\n","  Batch   940  of    988.    Elapsed: 0:08:47.\n","  Batch   950  of    988.    Elapsed: 0:08:53.\n","  Batch   960  of    988.    Elapsed: 0:08:58.\n","  Batch   970  of    988.    Elapsed: 0:09:04.\n","  Batch   980  of    988.    Elapsed: 0:09:10.\n","\n","  Average training loss generetor: 0.706\n","  Average training loss discriminator: 1.563\n","  Training epcoh took: 0:09:14\n","Saving the models...............................\n","\n","Running Test...\n","preds tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","preds tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","preds tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","  Accuracy: 0.594\n","  Test Loss: 0.921\n","  Test took: 0:00:00\n","\n","======== Epoch 4 / 5 ========\n","Training...\n","  Batch    10  of    988.    Elapsed: 0:00:06.\n","  Batch    20  of    988.    Elapsed: 0:00:11.\n","  Batch    30  of    988.    Elapsed: 0:00:17.\n","  Batch    40  of    988.    Elapsed: 0:00:22.\n","  Batch    50  of    988.    Elapsed: 0:00:28.\n","  Batch    60  of    988.    Elapsed: 0:00:34.\n","  Batch    70  of    988.    Elapsed: 0:00:39.\n","  Batch    80  of    988.    Elapsed: 0:00:45.\n","  Batch    90  of    988.    Elapsed: 0:00:51.\n","  Batch   100  of    988.    Elapsed: 0:00:56.\n","  Batch   110  of    988.    Elapsed: 0:01:02.\n","  Batch   120  of    988.    Elapsed: 0:01:07.\n","  Batch   130  of    988.    Elapsed: 0:01:13.\n","  Batch   140  of    988.    Elapsed: 0:01:19.\n","  Batch   150  of    988.    Elapsed: 0:01:24.\n","  Batch   160  of    988.    Elapsed: 0:01:30.\n","  Batch   170  of    988.    Elapsed: 0:01:35.\n","  Batch   180  of    988.    Elapsed: 0:01:41.\n","  Batch   190  of    988.    Elapsed: 0:01:47.\n","  Batch   200  of    988.    Elapsed: 0:01:52.\n","  Batch   210  of    988.    Elapsed: 0:01:58.\n","  Batch   220  of    988.    Elapsed: 0:02:03.\n","  Batch   230  of    988.    Elapsed: 0:02:09.\n","  Batch   240  of    988.    Elapsed: 0:02:15.\n","  Batch   250  of    988.    Elapsed: 0:02:20.\n","  Batch   260  of    988.    Elapsed: 0:02:26.\n","  Batch   270  of    988.    Elapsed: 0:02:31.\n","  Batch   280  of    988.    Elapsed: 0:02:37.\n","  Batch   290  of    988.    Elapsed: 0:02:43.\n","  Batch   300  of    988.    Elapsed: 0:02:48.\n","  Batch   310  of    988.    Elapsed: 0:02:54.\n","  Batch   320  of    988.    Elapsed: 0:02:59.\n","  Batch   330  of    988.    Elapsed: 0:03:05.\n","  Batch   340  of    988.    Elapsed: 0:03:11.\n","  Batch   350  of    988.    Elapsed: 0:03:16.\n","  Batch   360  of    988.    Elapsed: 0:03:22.\n","  Batch   370  of    988.    Elapsed: 0:03:27.\n","  Batch   380  of    988.    Elapsed: 0:03:33.\n","  Batch   390  of    988.    Elapsed: 0:03:39.\n","  Batch   400  of    988.    Elapsed: 0:03:44.\n","  Batch   410  of    988.    Elapsed: 0:03:50.\n","  Batch   420  of    988.    Elapsed: 0:03:56.\n","  Batch   430  of    988.    Elapsed: 0:04:01.\n","  Batch   440  of    988.    Elapsed: 0:04:07.\n","  Batch   450  of    988.    Elapsed: 0:04:12.\n","  Batch   460  of    988.    Elapsed: 0:04:18.\n","  Batch   470  of    988.    Elapsed: 0:04:24.\n","  Batch   480  of    988.    Elapsed: 0:04:29.\n","  Batch   490  of    988.    Elapsed: 0:04:35.\n","  Batch   500  of    988.    Elapsed: 0:04:40.\n","  Batch   510  of    988.    Elapsed: 0:04:46.\n","  Batch   520  of    988.    Elapsed: 0:04:52.\n","  Batch   530  of    988.    Elapsed: 0:04:57.\n","  Batch   540  of    988.    Elapsed: 0:05:03.\n","  Batch   550  of    988.    Elapsed: 0:05:08.\n","  Batch   560  of    988.    Elapsed: 0:05:14.\n","  Batch   570  of    988.    Elapsed: 0:05:20.\n","  Batch   580  of    988.    Elapsed: 0:05:25.\n","  Batch   590  of    988.    Elapsed: 0:05:31.\n","  Batch   600  of    988.    Elapsed: 0:05:36.\n","  Batch   610  of    988.    Elapsed: 0:05:42.\n","  Batch   620  of    988.    Elapsed: 0:05:48.\n","  Batch   630  of    988.    Elapsed: 0:05:53.\n","  Batch   640  of    988.    Elapsed: 0:05:59.\n","  Batch   650  of    988.    Elapsed: 0:06:04.\n","  Batch   660  of    988.    Elapsed: 0:06:10.\n","  Batch   670  of    988.    Elapsed: 0:06:16.\n","  Batch   680  of    988.    Elapsed: 0:06:21.\n","  Batch   690  of    988.    Elapsed: 0:06:27.\n","  Batch   700  of    988.    Elapsed: 0:06:32.\n","  Batch   710  of    988.    Elapsed: 0:06:38.\n","  Batch   720  of    988.    Elapsed: 0:06:44.\n","  Batch   730  of    988.    Elapsed: 0:06:49.\n","  Batch   740  of    988.    Elapsed: 0:06:55.\n","  Batch   750  of    988.    Elapsed: 0:07:00.\n","  Batch   760  of    988.    Elapsed: 0:07:06.\n","  Batch   770  of    988.    Elapsed: 0:07:12.\n","  Batch   780  of    988.    Elapsed: 0:07:17.\n","  Batch   790  of    988.    Elapsed: 0:07:23.\n","  Batch   800  of    988.    Elapsed: 0:07:29.\n","  Batch   810  of    988.    Elapsed: 0:07:34.\n","  Batch   820  of    988.    Elapsed: 0:07:40.\n","  Batch   830  of    988.    Elapsed: 0:07:45.\n","  Batch   840  of    988.    Elapsed: 0:07:51.\n","  Batch   850  of    988.    Elapsed: 0:07:57.\n","  Batch   860  of    988.    Elapsed: 0:08:02.\n","  Batch   870  of    988.    Elapsed: 0:08:08.\n","  Batch   880  of    988.    Elapsed: 0:08:13.\n","  Batch   890  of    988.    Elapsed: 0:08:19.\n","  Batch   900  of    988.    Elapsed: 0:08:25.\n","  Batch   910  of    988.    Elapsed: 0:08:30.\n","  Batch   920  of    988.    Elapsed: 0:08:36.\n","  Batch   930  of    988.    Elapsed: 0:08:41.\n","  Batch   940  of    988.    Elapsed: 0:08:47.\n","  Batch   950  of    988.    Elapsed: 0:08:53.\n","  Batch   960  of    988.    Elapsed: 0:08:58.\n","  Batch   970  of    988.    Elapsed: 0:09:04.\n","  Batch   980  of    988.    Elapsed: 0:09:09.\n","\n","  Average training loss generetor: 0.704\n","  Average training loss discriminator: 1.545\n","  Training epcoh took: 0:09:14\n","Saving the models...............................\n","\n","Running Test...\n","preds tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","preds tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","preds tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","  Accuracy: 0.594\n","  Test Loss: 0.918\n","  Test took: 0:00:00\n","\n","======== Epoch 5 / 5 ========\n","Training...\n","  Batch    10  of    988.    Elapsed: 0:00:06.\n","  Batch    20  of    988.    Elapsed: 0:00:11.\n","  Batch    30  of    988.    Elapsed: 0:00:17.\n","  Batch    40  of    988.    Elapsed: 0:00:22.\n","  Batch    50  of    988.    Elapsed: 0:00:28.\n","  Batch    60  of    988.    Elapsed: 0:00:34.\n","  Batch    70  of    988.    Elapsed: 0:00:39.\n","  Batch    80  of    988.    Elapsed: 0:00:45.\n","  Batch    90  of    988.    Elapsed: 0:00:51.\n","  Batch   100  of    988.    Elapsed: 0:00:56.\n","  Batch   110  of    988.    Elapsed: 0:01:02.\n","  Batch   120  of    988.    Elapsed: 0:01:07.\n","  Batch   130  of    988.    Elapsed: 0:01:13.\n","  Batch   140  of    988.    Elapsed: 0:01:19.\n","  Batch   150  of    988.    Elapsed: 0:01:24.\n","  Batch   160  of    988.    Elapsed: 0:01:30.\n","  Batch   170  of    988.    Elapsed: 0:01:35.\n","  Batch   180  of    988.    Elapsed: 0:01:41.\n","  Batch   190  of    988.    Elapsed: 0:01:47.\n","  Batch   200  of    988.    Elapsed: 0:01:52.\n","  Batch   210  of    988.    Elapsed: 0:01:58.\n","  Batch   220  of    988.    Elapsed: 0:02:03.\n","  Batch   230  of    988.    Elapsed: 0:02:09.\n","  Batch   240  of    988.    Elapsed: 0:02:15.\n","  Batch   250  of    988.    Elapsed: 0:02:20.\n","  Batch   260  of    988.    Elapsed: 0:02:26.\n","  Batch   270  of    988.    Elapsed: 0:02:31.\n","  Batch   280  of    988.    Elapsed: 0:02:37.\n","  Batch   290  of    988.    Elapsed: 0:02:43.\n","  Batch   300  of    988.    Elapsed: 0:02:48.\n","  Batch   310  of    988.    Elapsed: 0:02:54.\n","  Batch   320  of    988.    Elapsed: 0:02:59.\n","  Batch   330  of    988.    Elapsed: 0:03:05.\n","  Batch   340  of    988.    Elapsed: 0:03:11.\n","  Batch   350  of    988.    Elapsed: 0:03:16.\n","  Batch   360  of    988.    Elapsed: 0:03:22.\n","  Batch   370  of    988.    Elapsed: 0:03:27.\n","  Batch   380  of    988.    Elapsed: 0:03:33.\n","  Batch   390  of    988.    Elapsed: 0:03:39.\n","  Batch   400  of    988.    Elapsed: 0:03:44.\n","  Batch   410  of    988.    Elapsed: 0:03:50.\n","  Batch   420  of    988.    Elapsed: 0:03:55.\n","  Batch   430  of    988.    Elapsed: 0:04:01.\n","  Batch   440  of    988.    Elapsed: 0:04:07.\n","  Batch   450  of    988.    Elapsed: 0:04:12.\n","  Batch   460  of    988.    Elapsed: 0:04:18.\n","  Batch   470  of    988.    Elapsed: 0:04:23.\n","  Batch   480  of    988.    Elapsed: 0:04:29.\n","  Batch   490  of    988.    Elapsed: 0:04:35.\n","  Batch   500  of    988.    Elapsed: 0:04:40.\n","  Batch   510  of    988.    Elapsed: 0:04:46.\n","  Batch   520  of    988.    Elapsed: 0:04:52.\n","  Batch   530  of    988.    Elapsed: 0:04:57.\n","  Batch   540  of    988.    Elapsed: 0:05:03.\n","  Batch   550  of    988.    Elapsed: 0:05:08.\n","  Batch   560  of    988.    Elapsed: 0:05:14.\n","  Batch   570  of    988.    Elapsed: 0:05:20.\n","  Batch   580  of    988.    Elapsed: 0:05:25.\n","  Batch   590  of    988.    Elapsed: 0:05:31.\n","  Batch   600  of    988.    Elapsed: 0:05:36.\n","  Batch   610  of    988.    Elapsed: 0:05:42.\n","  Batch   620  of    988.    Elapsed: 0:05:48.\n","  Batch   630  of    988.    Elapsed: 0:05:53.\n","  Batch   640  of    988.    Elapsed: 0:05:59.\n","  Batch   650  of    988.    Elapsed: 0:06:04.\n","  Batch   660  of    988.    Elapsed: 0:06:10.\n","  Batch   670  of    988.    Elapsed: 0:06:16.\n","  Batch   680  of    988.    Elapsed: 0:06:21.\n","  Batch   690  of    988.    Elapsed: 0:06:27.\n","  Batch   700  of    988.    Elapsed: 0:06:32.\n","  Batch   710  of    988.    Elapsed: 0:06:38.\n","  Batch   720  of    988.    Elapsed: 0:06:44.\n","  Batch   730  of    988.    Elapsed: 0:06:49.\n","  Batch   740  of    988.    Elapsed: 0:06:55.\n","  Batch   750  of    988.    Elapsed: 0:07:00.\n","  Batch   760  of    988.    Elapsed: 0:07:06.\n","  Batch   770  of    988.    Elapsed: 0:07:12.\n","  Batch   780  of    988.    Elapsed: 0:07:17.\n","  Batch   790  of    988.    Elapsed: 0:07:23.\n","  Batch   800  of    988.    Elapsed: 0:07:28.\n","  Batch   810  of    988.    Elapsed: 0:07:34.\n","  Batch   820  of    988.    Elapsed: 0:07:40.\n","  Batch   830  of    988.    Elapsed: 0:07:45.\n","  Batch   840  of    988.    Elapsed: 0:07:51.\n","  Batch   850  of    988.    Elapsed: 0:07:57.\n","  Batch   860  of    988.    Elapsed: 0:08:02.\n","  Batch   870  of    988.    Elapsed: 0:08:08.\n","  Batch   880  of    988.    Elapsed: 0:08:13.\n","  Batch   890  of    988.    Elapsed: 0:08:19.\n","  Batch   900  of    988.    Elapsed: 0:08:25.\n","  Batch   910  of    988.    Elapsed: 0:08:30.\n","  Batch   920  of    988.    Elapsed: 0:08:36.\n","  Batch   930  of    988.    Elapsed: 0:08:42.\n","  Batch   940  of    988.    Elapsed: 0:08:47.\n","  Batch   950  of    988.    Elapsed: 0:08:53.\n","  Batch   960  of    988.    Elapsed: 0:08:58.\n","  Batch   970  of    988.    Elapsed: 0:09:04.\n","  Batch   980  of    988.    Elapsed: 0:09:10.\n","\n","  Average training loss generetor: 0.703\n","  Average training loss discriminator: 1.544\n","  Training epcoh took: 0:09:14\n","Saving the models...............................\n","\n","Running Test...\n","preds tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","preds tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","preds tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","  Accuracy: 0.594\n","  Test Loss: 0.969\n","  Test took: 0:00:00\n"]}]},{"cell_type":"code","source":["# Loading the saved model\n","transformer = torch.load('transformer')\n","discriminator = torch.load('discriminator')"],"metadata":{"id":"iJ7VJH3K7jhq","executionInfo":{"status":"ok","timestamp":1654871602966,"user_tz":-60,"elapsed":12,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["print(\"\")\n","print(\"Running Test...\")\n","\n","t0 = time.time()\n","\n","# Put the model in evaluation mode--the dropout layers behave differently\n","# during evaluation.\n","transformer.eval() #maybe redundant\n","discriminator.eval()\n","\n","# Tracking variables \n","total_test_accuracy = 0\n","\n","total_test_loss = 0\n","nb_test_steps = 0\n","\n","all_preds = []\n","all_labels_ids = []\n","\n","#loss\n","nll_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n","\n","# Evaluate data for one epoch\n","for batch in test_dataloader:\n","    \n","    # Unpack this training batch from our dataloader. \n","    b_input_ids = batch[0].to(device)\n","    b_input_mask = batch[1].to(device)\n","    b_labels = batch[2].to(device)\n","    \n","    # Tell pytorch not to bother with constructing the compute graph during\n","    # the forward pass, since this is only needed for backprop (training).\n","    with torch.no_grad():        \n","        model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n","        hidden_states = model_outputs[-1]\n","        _, logits, probs = discriminator(hidden_states)\n","        ###log_probs = F.log_softmax(probs[:,1:], dim=-1)\n","        filtered_logits = logits[:,0:-1]\n","        # Accumulate the test loss.\n","        total_test_loss += nll_loss(filtered_logits, b_labels)\n","        \n","    # Accumulate the predictions and the input labels\n","    _, preds = torch.max(filtered_logits, 1)\n","    all_preds += preds.detach().cpu()\n","    all_labels_ids += b_labels.detach().cpu()\n","\n","# Report the final accuracy for this validation run.\n","all_preds = torch.stack(all_preds).numpy()\n","all_labels_ids = torch.stack(all_labels_ids).numpy()\n","test_accuracy = np.sum(all_preds == all_labels_ids) / len(all_preds)\n","print(\"  Accuracy: {0:.3f}\".format(test_accuracy))\n","\n","# Calculate the average loss over all of the batches.\n","avg_test_loss = total_test_loss / len(test_dataloader)\n","avg_test_loss = avg_test_loss.item()\n","\n","# Measure how long the validation run took.\n","test_time = format_time(time.time() - t0)\n","  \n","print(\"  Test Loss: {0:.3f}\".format(avg_test_loss))\n","print(\"  Test took: {:}\".format(test_time))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rvAOFap97j6B","executionInfo":{"status":"ok","timestamp":1654871603742,"user_tz":-60,"elapsed":779,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}},"outputId":"b95943d9-57a2-440f-ba0e-3ab5295937c9"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Running Test...\n","  Accuracy: 0.594\n","  Test Loss: 0.969\n","  Test took: 0:00:00\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"0T0j41l1Zn7Y","executionInfo":{"status":"ok","timestamp":1654871603742,"user_tz":-60,"elapsed":18,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["all_preds, len(all_preds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r0oZQ_qyYgLG","executionInfo":{"status":"ok","timestamp":1654871603742,"user_tz":-60,"elapsed":17,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}},"outputId":"104e1028-5401-4fa7-a90b-87278a087f34"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0]), 96)"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["all_labels_ids"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tJ6zcP3bYmg-","executionInfo":{"status":"ok","timestamp":1654871603743,"user_tz":-60,"elapsed":16,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}},"outputId":"423a58d0-b539-4fc4-9eb7-96f1267bdd05"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 1, 1, 0, 2, 0,\n","       0, 1, 0, 0, 2, 2, 0, 2, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 2, 2, 0,\n","       0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 1, 2, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0,\n","       0, 0, 0, 1, 2, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 2, 1, 2, 0,\n","       0, 2, 0, 0, 0, 2, 1, 0])"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, classification_report\n","\n","print(confusion_matrix(all_labels_ids, all_preds))\n","print(classification_report(all_labels_ids, all_preds))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2TabwR5AZdjG","executionInfo":{"status":"ok","timestamp":1654871603743,"user_tz":-60,"elapsed":14,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}},"outputId":"4ed57061-f292-4391-f2d2-03ee24f8c74c"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["[[57  0  0]\n"," [11  0  0]\n"," [28  0  0]]\n","              precision    recall  f1-score   support\n","\n","           0       0.59      1.00      0.75        57\n","           1       0.00      0.00      0.00        11\n","           2       0.00      0.00      0.00        28\n","\n","    accuracy                           0.59        96\n","   macro avg       0.20      0.33      0.25        96\n","weighted avg       0.35      0.59      0.44        96\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["for stat in training_stats:\n","  print(stat)\n","\n","print(\"\\nTraining complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fMwVBlaj786a","executionInfo":{"status":"ok","timestamp":1654871603743,"user_tz":-60,"elapsed":11,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}},"outputId":"6fd17163-7375-40e5-86ff-0d6da2c33235"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["{'epoch': 1, 'Training Loss generator': 0.7219031508333287, 'Training Loss discriminator': 1.5742417722940445, 'Valid. Loss': 0.9294412136077881, 'Valid. Accur.': 0.59375, 'Training Time': '0:09:10', 'Test Time': '0:00:00'}\n","{'epoch': 2, 'Training Loss generator': 0.7106958210830264, 'Training Loss discriminator': 1.578976390936114, 'Valid. Loss': 0.9196569323539734, 'Valid. Accur.': 0.59375, 'Training Time': '0:09:14', 'Test Time': '0:00:00'}\n","{'epoch': 3, 'Training Loss generator': 0.7060927536926771, 'Training Loss discriminator': 1.563287043921378, 'Valid. Loss': 0.9209429621696472, 'Valid. Accur.': 0.59375, 'Training Time': '0:09:14', 'Test Time': '0:00:00'}\n","{'epoch': 4, 'Training Loss generator': 0.7043295049594964, 'Training Loss discriminator': 1.5448446804695284, 'Valid. Loss': 0.9180113673210144, 'Valid. Accur.': 0.59375, 'Training Time': '0:09:14', 'Test Time': '0:00:00'}\n","{'epoch': 5, 'Training Loss generator': 0.703133051694646, 'Training Loss discriminator': 1.5441613812678257, 'Valid. Loss': 0.9694880247116089, 'Valid. Accur.': 0.59375, 'Training Time': '0:09:14', 'Test Time': '0:00:00'}\n","\n","Training complete!\n","Total training took 0:46:16 (h:mm:ss)\n"]}]}]}