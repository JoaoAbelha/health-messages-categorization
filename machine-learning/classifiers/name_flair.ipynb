{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"name_flair.ipynb","provenance":[],"authorship_tag":"ABX9TyOIu8EwTuuJgyG12mMHSMPL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uhN3Clb4Ism0","executionInfo":{"status":"ok","timestamp":1649689231612,"user_tz":-60,"elapsed":52045,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}},"outputId":"f47bd306-344b-4032-bfd5-a761059ea7da"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting flair\n","  Downloading flair-0.11.1-py3-none-any.whl (401 kB)\n","\u001b[K     |████████████████████████████████| 401 kB 7.4 MB/s \n","\u001b[?25hCollecting ftfy\n","  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n","\u001b[K     |████████████████████████████████| 53 kB 2.0 MB/s \n","\u001b[?25hCollecting janome\n","  Downloading Janome-0.4.2-py2.py3-none-any.whl (19.7 MB)\n","\u001b[K     |████████████████████████████████| 19.7 MB 52.2 MB/s \n","\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.2.6)\n","Collecting konoha<5.0.0,>=4.0.0\n","  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n","Collecting gdown==3.12.2\n","  Downloading gdown-3.12.2.tar.gz (8.2 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Collecting langdetect\n","  Downloading langdetect-1.0.9.tar.gz (981 kB)\n","\u001b[K     |████████████████████████████████| 981 kB 44.0 MB/s \n","\u001b[?25hCollecting sentencepiece==0.1.95\n","  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 49.3 MB/s \n","\u001b[?25hCollecting more-itertools~=8.8.0\n","  Downloading more_itertools-8.8.0-py3-none-any.whl (48 kB)\n","\u001b[K     |████████████████████████████████| 48 kB 6.4 MB/s \n","\u001b[?25hCollecting segtok>=1.5.7\n","  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n","Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.63.0)\n","Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n","Collecting bpemb>=0.3.2\n","  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n","Collecting hyperopt>=0.2.7\n","  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 48.8 MB/s \n","\u001b[?25hRequirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.10.0+cu111)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2019.12.20)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.9)\n","Collecting wikipedia-api\n","  Downloading Wikipedia-API-0.5.4.tar.gz (18 kB)\n","Collecting pptree\n","  Downloading pptree-3.1.tar.gz (3.0 kB)\n","Collecting deprecated>=1.2.4\n","  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n","Collecting huggingface-hub\n","  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 6.6 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.2)\n","Collecting mpld3==0.3\n","  Downloading mpld3-0.3.tar.gz (788 kB)\n","\u001b[K     |████████████████████████████████| 788 kB 44.3 MB/s \n","\u001b[?25hCollecting transformers>=4.0.0\n","  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 19.2 MB/s \n","\u001b[?25hCollecting sqlitedict>=1.6.0\n","  Downloading sqlitedict-2.0.0.tar.gz (46 kB)\n","\u001b[K     |████████████████████████████████| 46 kB 4.7 MB/s \n","\u001b[?25hCollecting conllu>=4.0\n","  Downloading conllu-4.4.1-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (1.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (3.6.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (1.15.0)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bpemb>=0.3.2->flair) (1.21.5)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.14.0)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->flair) (5.2.1)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->flair) (1.4.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (0.16.0)\n","Collecting py4j\n","  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n","\u001b[K     |████████████████████████████████| 199 kB 63.9 MB/s \n","\u001b[?25hRequirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (2.6.3)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (1.3.0)\n","Collecting importlib-metadata<4.0.0,>=3.7.0\n","  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n","Collecting requests\n","  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.2 MB/s \n","\u001b[?25hCollecting overrides<4.0.0,>=3.0.0\n","  Downloading overrides-3.1.0.tar.gz (11 kB)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.10.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.7.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.4.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (3.0.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.24.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2021.10.8)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.1.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (21.3)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 37.8 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 45.0 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 50.9 MB/s \n","\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.7.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->flair) (7.1.2)\n","Building wheels for collected packages: gdown, mpld3, overrides, sqlitedict, langdetect, pptree, wikipedia-api\n","  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gdown: filename=gdown-3.12.2-py3-none-any.whl size=9692 sha256=00544630411a83c56850663647e9d21e4a4538e87f68c5ac769b0ed6b7c30025\n","  Stored in directory: /root/.cache/pip/wheels/ba/e0/7e/726e872a53f7358b4b96a9975b04e98113b005cd8609a63abc\n","  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116702 sha256=5a88959ba7fd828085302b0388b6058e4940df617540f5e538b853669386b386\n","  Stored in directory: /root/.cache/pip/wheels/26/70/6a/1c79e59951a41b4045497da187b2724f5659ca64033cf4548e\n","  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10187 sha256=eca5a19b54f04f5e9b046dda22eb978a04b73552312a3c56be6f85fceac698fe\n","  Stored in directory: /root/.cache/pip/wheels/3a/0d/38/01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n","  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sqlitedict: filename=sqlitedict-2.0.0-py3-none-any.whl size=15736 sha256=c1c491d2c8fb1190a00bea09d1a4206c3873225c7bc30e6f6f11754dc95f7c56\n","  Stored in directory: /root/.cache/pip/wheels/96/dd/2e/0ed4a25cb73fc30c7ea8d10b50acb7226175736067e40a7ea3\n","  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=8499c9199ee28593f6853e649b9cb6825b2b22aae478761ca7638ee025c2ddd4\n","  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n","  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4629 sha256=e1547de300b6b99bb4645ad10eb27b41633a80fb86cc99a71ec3644b5536dd81\n","  Stored in directory: /root/.cache/pip/wheels/9e/e8/7d/a9c3c19b4722608a0d8b05a38c36bc3f230c43becd2a46794b\n","  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wikipedia-api: filename=Wikipedia_API-0.5.4-py3-none-any.whl size=13477 sha256=30fab7ebd873d3087657ea224b976043998d874c0dfd33648ff0a8b01e3e8e3a\n","  Stored in directory: /root/.cache/pip/wheels/d3/24/56/58ba93cf78be162451144e7a9889603f437976ef1ae7013d04\n","Successfully built gdown mpld3 overrides sqlitedict langdetect pptree wikipedia-api\n","Installing collected packages: requests, pyyaml, importlib-metadata, tokenizers, sentencepiece, sacremoses, py4j, overrides, huggingface-hub, wikipedia-api, transformers, sqlitedict, segtok, pptree, mpld3, more-itertools, langdetect, konoha, janome, hyperopt, gdown, ftfy, deprecated, conllu, bpemb, flair\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib-metadata 4.11.3\n","    Uninstalling importlib-metadata-4.11.3:\n","      Successfully uninstalled importlib-metadata-4.11.3\n","  Attempting uninstall: more-itertools\n","    Found existing installation: more-itertools 8.12.0\n","    Uninstalling more-itertools-8.12.0:\n","      Successfully uninstalled more-itertools-8.12.0\n","  Attempting uninstall: hyperopt\n","    Found existing installation: hyperopt 0.1.2\n","    Uninstalling hyperopt-0.1.2:\n","      Successfully uninstalled hyperopt-0.1.2\n","  Attempting uninstall: gdown\n","    Found existing installation: gdown 4.2.2\n","    Uninstalling gdown-4.2.2:\n","      Successfully uninstalled gdown-4.2.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","markdown 3.3.6 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 3.10.1 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed bpemb-0.3.3 conllu-4.4.1 deprecated-1.2.13 flair-0.11.1 ftfy-6.1.1 gdown-3.12.2 huggingface-hub-0.5.1 hyperopt-0.2.7 importlib-metadata-3.10.1 janome-0.4.2 konoha-4.6.5 langdetect-1.0.9 more-itertools-8.8.0 mpld3-0.3 overrides-3.1.0 pptree-3.1 py4j-0.10.9.5 pyyaml-6.0 requests-2.27.1 sacremoses-0.0.49 segtok-1.5.11 sentencepiece-0.1.95 sqlitedict-2.0.0 tokenizers-0.11.6 transformers-4.18.0 wikipedia-api-0.5.4\n"]}],"source":["! pip install flair"]},{"cell_type":"code","source":["from flair.models import TARSClassifier\n","from flair.data import Sentence\n","\n","# 1. Load our pre-trained TARS model for English\n","tars = TARSClassifier.load('tars-base')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dwkMIO9fIyzn","executionInfo":{"status":"ok","timestamp":1649689393503,"user_tz":-60,"elapsed":4948,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}},"outputId":"c57614af-ebf5-4a0a-cf5f-bbfbbd5788c6"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-04-11 15:03:07,918 loading file /root/.flair/models/tars-base-v8.pt\n","Sentence: \"I need someone to help me here\" → giving support (0.6992)\n"]}]},{"cell_type":"code","source":["# 2. Prepare a test sentence\n","sentence = Sentence(\"Cans someone help me? \")\n","\n","# 3. Define some classes that you want to predict using descriptive names\n","classes = [\"seeking_support\", \"giving_support\", \"network_support\"]\n","\n","#4. Predict for these classes\n","tars.predict_zero_shot(sentence, classes)\n","\n","# Print sentence with predicted labels\n","print(sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ASsEMfvJqiL","executionInfo":{"status":"ok","timestamp":1649689565299,"user_tz":-60,"elapsed":411,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}},"outputId":"9029cea1-1254-4ba6-a087-b35705149eb4"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentence: \"Cans someone help me ?\" → giving_support (0.8261)\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TrmxPwt9KezC","executionInfo":{"status":"ok","timestamp":1649689645702,"user_tz":-60,"elapsed":18844,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}},"outputId":"369fe02e-d1f2-4f2e-81f8-138c1d4ee27f"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["\n","\n","import pandas as pd\n","\n","data = pd.read_csv('/content/gdrive/My Drive/Mestrado/initial_dataset.csv')"],"metadata":{"id":"akEsfjTWKgAR","executionInfo":{"status":"ok","timestamp":1649690010024,"user_tz":-60,"elapsed":253,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["\n","data.iloc[0:int(len(data)*0.8)].to_csv('train.csv', sep='\\t', index = False, header = False)\n","data.iloc[int(len(data)*0.8):int(len(data)*0.9)].to_csv('test.csv', sep='\\t', index = False, header = False)\n","data.iloc[int(len(data)*0.9):].to_csv('dev.csv', sep='\\t', index = False, header = False);"],"metadata":{"id":"hUzB95JfKjj9","executionInfo":{"status":"ok","timestamp":1649690013284,"user_tz":-60,"elapsed":310,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["import flair\n","dir(flair.training_utils)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZpiGPAv1Nrux","executionInfo":{"status":"ok","timestamp":1649690547742,"user_tz":-60,"elapsed":275,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}},"outputId":"f18ce49e-d29b-4c60-bc54-08a73a75364c"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['AnnealOnPlateau',\n"," 'DT',\n"," 'DataPoint',\n"," 'Dataset',\n"," 'Dict',\n"," 'Dictionary',\n"," 'Enum',\n"," 'EvaluationMetric',\n"," 'List',\n"," 'MetricRegression',\n"," 'Optimizer',\n"," 'Optional',\n"," 'Path',\n"," 'Result',\n"," 'Sentence',\n"," 'Union',\n"," 'WeightExtractor',\n"," '__builtins__',\n"," '__cached__',\n"," '__doc__',\n"," '__file__',\n"," '__loader__',\n"," '__name__',\n"," '__package__',\n"," '__spec__',\n"," '_iter_dataset',\n"," 'add_file_handler',\n"," 'convert_labels_to_one_hot',\n"," 'defaultdict',\n"," 'flair',\n"," 'identify_dynamic_embeddings',\n"," 'inf',\n"," 'init_output_file',\n"," 'log',\n"," 'log_line',\n"," 'logging',\n"," 'mean_absolute_error',\n"," 'mean_squared_error',\n"," 'pearsonr',\n"," 'random',\n"," 'reduce',\n"," 'spearmanr',\n"," 'store_embeddings']"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["from flair.data_fetcher import NLPTaskDataFetcher\n","from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentLSTMEmbeddings\n","from flair.models import TextClassifier\n","from flair.trainers import ModelTrainer\n","from pathlib import Path\n","\n","\n","corpus = flair.data_fetcher.  NLPTaskDataFetcher.load_classification_corpus(Path('./'), test_file='test.csv', dev_file='dev.csv', train_file='train.csv')\n","\n","\n","word_embeddings = [WordEmbeddings('glove'), FlairEmbeddings('news-forward-fast'), FlairEmbeddings('news-backward-fast')]\n","\n","document_embeddings = DocumentLSTMEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)\n","\n","classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=True)\n","trainer = ModelTrainer(classifier, corpus)\n","trainer.train('./', max_epochs=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":367},"id":"AlpT14cgKA44","executionInfo":{"status":"error","timestamp":1649690277796,"user_tz":-60,"elapsed":19,"user":{"displayName":"João Paulo","userId":"17940923821633124910"}},"outputId":"63ca2daa-17c5-4d15-e798-e0e49ac8eb5d"},"execution_count":22,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-5a7ac5e6ba65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_fetcher\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNLPTaskDataFetcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordEmbeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlairEmbeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDocumentLSTMEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'flair.data_fetcher'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]}]}